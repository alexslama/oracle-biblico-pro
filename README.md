# ğŸ”® Oracle BÃ­blico PRO

**Sistema de AnÃ¡lise BÃ­blica Profissional com IA**

Fine-tuning Llama3.1 + RAG especializado em textos hebraicos e bÃ­blicos. Otimizado para MacBook M1/Max e Google Cloud.

---

## ğŸ¯ Capacidades

âœ… **AnÃ¡lise em 5 Camadas**
- LingÃ¼Ã­stica (Hebraico/Grego antigos)
- NumÃ©rica (Gematria com valores hebraicos)
- HistÃ³rica (Contexto arqueolÃ³gico)
- TeolÃ³gica (Conceitos divinos)
- Integrada (SÃ­ntese completa)

âœ… **Processamento Estruturado**
- 5 templates de anÃ¡lise especializados
- ValidaÃ§Ã£o automÃ¡tica de qualidade
- Rastreambiilidade de fontes

âœ… **InteligÃªncia Contextual**
- RAG com vector database (Chroma)
- 5+ documentos de contexto por query
- Cross-referencing automÃ¡tico

âœ… **Qualidade Garantida**
- Tests unitÃ¡rios completos
- ValidaÃ§Ã£o de respostas
- Scoring automÃ¡tico (0-100%)

---

## ğŸš€ ComeÃ§ar RÃ¡pido

### PrÃ©-requisitos
- Python 3.9+
- Ollama (`ollama.ai`)
- 64GB RAM (recomendado para fine-tuning)

### InstalaÃ§Ã£o (MacBook M1/Max)

```bash
# 1. Clonar repo
git clone https://github.com/alexslama/oracle-biblico-pro
cd oracle-biblico-pro

# 2. Criar ambiente virtual (Apple Silicon)
arch -arm64 python3 -m venv venv
source venv/bin/activate

# 3. Instalar dependÃªncias
pip install -r requirements.txt

# 4. Executar setup
bash setup.sh
```

---

## ğŸ“š Etapas de ExecuÃ§Ã£o

### Etapa 1: Coleta de Dados (2-3 horas)

```bash
python scripts/01_collect_data.py
```

**O que faz:**
- Baixa corpus bÃ­blico de Sefaria.org
- Processa textos hebraicos
- Enriquece com traduÃ§Ãµes em portuguÃªs

### Etapa 2: Preparar Dados de Treinamento (1 hora)

```bash
python scripts/02_prepare_training_data.py
```

**O que faz:**
- Cria pares instruction-response
- Gera 3 variaÃ§Ãµes de prompts por verso
- Formata para JSONL

### Etapa 3: Fine-tune Llama3.1 (4-8 horas em M1 Max)

```bash
python scripts/03_finetune_llama.py
```

**Configurado para:**
- Apple Silicon acceleration
- 8-bit quantization
- 3 Ã©pocas de treinamento
- ValidaÃ§Ã£o em tempo real

### Etapa 4: Construir Sistema RAG (1-2 horas)

```bash
python scripts/04_build_rag.py
```

**Cria:**
- Vector database com Chroma
- Ãndices de busca de similaridade
- RecuperaÃ§Ã£o contextual

### Etapa 5: Pipeline Completo de AnÃ¡lise (ContÃ­nuo)

```bash
python scripts/05_analysis_pipeline.py
```

**Executa:**
- AnÃ¡lise de mÃºltiplos versÃ­culos
- CÃ¡lculo de gematria
- ValidaÃ§Ã£o de qualidade

### Etapa 6: Testes e ValidaÃ§Ã£o

```bash
python scripts/06_testing_validation.py
```

---

## â˜ï¸ Deploy no Google Cloud

### Setup Inicial

```bash
# 1. Autenticar com Google Cloud
gcloud auth login
gcloud config set project seu-projeto-id

# 2. Criar Compute Engine Instance
gcloud compute instances create oracle-biblico \
    --machine-type=n1-standard-8 \
    --accelerator=type=nvidia-tesla-p100,count=1 \
    --image-family=pytorch-latest-cu121 \
    --image-project=deeplearning-platform-release

# 3. SSH na instÃ¢ncia
gcloud compute ssh oracle-biblico

# 4. Clonar e instalar
git clone https://github.com/alexslama/oracle-biblico-pro
cd oracle-biblico-pro
pip install -r requirements.txt
```

### Executar Fine-tune na GPU

```bash
# Com GPU P100, fine-tune leva ~2 horas
python scripts/03_finetune_llama.py --use-gpu
```

---

## ğŸ“ Estrutura do Projeto

```
oracle-biblico-pro/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados brutos
â”‚   â”‚   â”œâ”€â”€ hebrew/
â”‚   â”‚   â”œâ”€â”€ greek/
â”‚   â”‚   â””â”€â”€ portuguese/
â”‚   â”œâ”€â”€ processed/              # Dados processados
â”‚   â”‚   â”œâ”€â”€ training_data/
â”‚   â”‚   â”œâ”€â”€ rag_corpus/
â”‚   â”‚   â””â”€â”€ validation/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/            # Checkpoints de treinamento
â”‚   â””â”€â”€ final/                  # Modelo fine-tunado final
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_collect_data.py
â”‚   â”œâ”€â”€ 02_prepare_training_data.py
â”‚   â”œâ”€â”€ 03_finetune_llama.py
â”‚   â”œâ”€â”€ 04_build_rag.py
â”‚   â”œâ”€â”€ 05_analysis_pipeline.py
â”‚   â””â”€â”€ 06_testing_validation.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb
â”‚   â””â”€â”€ results_visualization.ipynb
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â”œâ”€â”€ training_config.yaml
â”‚   â””â”€â”€ rag_config.yaml
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ analyses/               # AnÃ¡lises geradas
â”‚   â”œâ”€â”€ logs/                   # Logs de execuÃ§Ã£o
â”‚   â””â”€â”€ reports/                # RelatÃ³rios de qualidade
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.sh
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **LLM**: Llama 3.1 (13B ou 70B)
- **RAG**: LangChain + Chroma
- **Embeddings**: Sentence-Transformers (multilingual)
- **Hardware**: MacBook M1/Max ou Google Cloud GPU
- **Framework**: PyTorch + Hugging Face

---

## ğŸ“Š Performance Esperada

### MacBook M1 Max (64GB RAM)
- **Coleta de dados**: 2-3 horas
- **PreparaÃ§Ã£o**: 1 hora
- **Fine-tune**: 4-6 horas (3 Ã©pocas)
- **RAG**: 1-2 horas
- **Total**: ~8-12 horas para setup completo

### Google Cloud (GPU P100)
- **Fine-tune**: 1-2 horas
- **Total**: ~5-6 horas para setup completo

---

## ğŸ“ Exemplo de Uso

```python
from oracle_biblico import BiblicalOracleSystem

# Inicializar sistema
oracle = BiblicalOracleSystem(model="biblical_llama3.1")

# Analisar verso
result = oracle.analyze(
    reference="GÃªnesis 1:1",
    analysis_type="comprehensive",
    depth_level=5
)

print(result["analysis"])
print(f"Qualidade: {result['quality_score']:.2%}")
```

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/amazing`)
3. Commit suas mudanÃ§as (`git commit -m 'Add amazing feature'`)
4. Push para a branch (`git push origin feature/amazing`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

MIT License - veja LICENSE para detalhes

---

## ğŸ‘¤ Autor

**Alex Lama** - alexernestslama@gmail.com

- ğŸ¬ Video Producer @ Unlogice Records
- ğŸ¤– AI/ML Specialist
- ğŸ“– Biblical Text Processing Expert

---

## ğŸ“ Suporte

Problemas ou dÃºvidas? Abra uma issue no GitHub!

---


## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Interface Web (Recomendado)

#### 1. Iniciar o servidor

```bash
# Ativar ambiente virtual
source venv/bin/activate

# Iniciar Flask
python3 app.py
```

O servidor rodarÃ¡ em `http://localhost:5000`

#### 2. Abrir no navegador

- Acesse `http://localhost:5000` no seu navegador
- Interface visual Matrix-style com autenticaÃ§Ã£o
- AnÃ¡lise em tempo real com 5 camadas bÃ­blicas

---

### OpÃ§Ã£o 2: API REST (Programadores)

#### 2.1. Health Check

```bash
curl http://localhost:5000/api/health
```

**Resposta:**
```json
{"status": "ok", "version": "1.0.0"}
```

#### 2.2. Analisar Texto BÃ­blico

```bash
curl -X POST http://localhost:5000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"query": "Profecia sobre cometa na biblia"}'
```

**Resposta (Exemplo):**
```json
{
  "query": "Profecia sobre cometa na biblia",
  "analysis": {
    "linguistica": {"resultado": "..."},
    "numerica": {"resultado": "..."},
    "historica": {"resultado": "..."},
    "teologica": {"resultado": "..."},
    "integrada": {"resultado": "..."}
  },
  "timestamp": "2025-12-10T03:45:22"
}
```

#### 2.3. Obter Resultados Anteriores

```bash
curl http://localhost:5000/api/results
```

---

### OpÃ§Ã£o 3: CLI - Linha de Comando

```bash
# Ativar ambiente
source venv/bin/activate

# Executar anÃ¡lise
python3 scripts/analysis_pipeline.py "Sua pergunta bÃ­blica aqui"

# Ver resultado em JSON formatado
cat outputs/analysis_results.json | python3 -m json.tool
```

**Exemplo:**

```bash
python3 scripts/analysis_pipeline.py "Significado de Apocalipse 12:1"
```

Resultados salvos em: `outputs/analysis_results.json`

---

### OpÃ§Ã£o 4: IntegraÃ§Ã£o com Open WebUI

#### Se vocÃª usa Open WebUI (Ollama):

```bash
# Terminal 1: Iniciar ollama (se necessÃ¡rio)
ollama serve

# Terminal 2: Iniciar Flask API
source venv/bin/activate
python3 app.py

# Terminal 3: Acessar Open WebUI
# http://localhost:3000
```

Configure o modelo customizado para chamar:
```
http://localhost:5000/api/analyze
```

---

## ğŸ”§ ConfiguraÃ§Ãµes

### VariÃ¡veis de Ambiente

Crie um `.env` file (opcional):

```env
FLASK_ENV=development
FLASK_PORT=5000
LLAMA_MODEL=llama2
RAG_ENABLED=true
CHROMA_DB_PATH=./chromadb
```

### Melhorar Performance

**M1/M2 Mac:**
```bash
# Use aceleraÃ§Ã£o GPU
export PYTORCH_ENABLE_MPS_FALLBACK=1
python3 app.py
```

**Google Cloud:**
```bash
# Deploy com gcloud
gcloud app deploy
```

---

## ğŸ“Š Exemplos de Queries BÃ­blicas

```bash
# AnÃ¡lise de passagens
"Qual Ã© o significado de JoÃ£o 1:1?"

# AnÃ¡lise de conceitos
"O que significa 'Logos' no Evangelho de JoÃ£o?"

# AnÃ¡lise de profecias
"Profecia sobre cometa na BÃ­blia"

# AnÃ¡lise de nÃºmeros
"Significado numerolÃ³gico de 666 em Apocalipse"

# AnÃ¡lise histÃ³rica
"Contexto histÃ³rico de BelÃ©m no nascimento de Jesus"
```

---

## ğŸ› Troubleshooting

### Problema: Porta 5000 jÃ¡ em uso

```bash
# Encontrar processo usando porta
lsof -ti:5000 | xargs kill -9

# Ou usar outra porta
FLASK_PORT=5001 python3 app.py
```

### Problema: ModuleNotFoundError

```bash
# Reinstalar dependÃªncias
source venv/bin/activate
pip install --upgrade -r requirements.txt
```

### Problema: Erro de Python 3.15

```bash
# Usar Python 3.12
brew install python@3.12
python3.12 -m venv venv_new
source venv_new/bin/activate
pip install -r requirements.txt
```

---

## ğŸ’± PrÃ³ximos Passos

- [ ] Deploy em produÃ§Ã£o (Heroku/AWS/GCP)
- [ ] Adicionar autenticaÃ§Ã£o OAuth2
- [ ] Mobile app (React Native)
- [ ] Dashboard de anÃ¡lises histÃ³ricas
- [ ] Exportar resultados (PDF/Excel)

**Criado com â¤ï¸ para questÃ£o bÃ­blica profunda e anÃ¡lise estruturada**
